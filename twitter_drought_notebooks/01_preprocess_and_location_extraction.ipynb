{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46220afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets/tweets_22.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aead1e",
   "metadata": {},
   "source": [
    "### preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983e915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing tweet text by removing URLs, mentions, non-word characters, \n",
    "# retweet markers (RT), and converting text to lowercase.\n",
    "\n",
    "df['process_text'] = df['text'].str.replace(r'https\\S+', '', regex=True).str.replace(r'\\@\\w+|[^\\w\\s]', '', regex=True).str.replace(r'\\bRT\\b', '', regex=True).str.lower()\n",
    "\n",
    "# Filtering out tweets containing any of the specified keywords\n",
    "\n",
    "keywords = ['cinema', 'film', 'attila', 'unni', 'virzi', 'virzì', 'boxoffice', 'venezia79']\n",
    "keywords = r'(?:' + '|'.join(keywords) + r')'\n",
    "\n",
    "df_filtered = df[~df['text'].str.contains(keywords, case=False, na=False)]\n",
    "df_filtered = df_filtered.dropna(subset=['process_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate tweets based on fuzzy matching (similarity threshold > 90)\n",
    "\n",
    "def remove_dup(df):\n",
    "    uniques = []\n",
    "    duplicates = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        tweet = row['process_text']\n",
    "        if not any(fuzz.ratio(tweet, unique) > 90 for unique in uniques):\n",
    "            uniques.append(tweet)\n",
    "        else:\n",
    "            duplicates.append(index)\n",
    "\n",
    "    return df.drop(index=duplicates)\n",
    "\n",
    "df_processed = remove_dup(df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f030b91",
   "metadata": {},
   "source": [
    "### location extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2a3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# !python -m spacy download it_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_it = spacy.load(\"it_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e61a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Italian geographic entities (LOC, GPE) from text\n",
    "\n",
    "def find_loc_gpe_it(text):\n",
    "    doc = nlp_it(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['LOC', 'GPE']:\n",
    "            entities.append(ent.text)\n",
    "    return entities\n",
    "\n",
    "df_processed['loc'] = df_processed['process_text'].apply(find_loc_gpe_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5072a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Italian geonames for matching\n",
    "\n",
    "geonames = pd.read_excel('tweets/geonames.xlsx')\n",
    "locations_it = [item.lower() if isinstance(item, str) else item for item in geonames[2].tolist()]\n",
    "\n",
    "df_italy = df_processed[df_processed['loc'].apply(lambda x: any(loc in x for loc in locations_it))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from requests.exceptions import RequestException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping keywords to custom NUTS2 regions\n",
    "\n",
    "location_to_nuts2_custom = {\n",
    "    'po': ['ITC1', 'ITC4', 'ITH3', 'ITH4', 'ITH5'],\n",
    "    'po valley': ['ITC1', 'ITC4', 'ITH3', 'ITH4', 'ITH5'],\n",
    "    'po river': ['ITC1', 'ITC4', 'ITH3', 'ITH4', 'ITH5'],\n",
    "    'the po valley': ['ITC1', 'ITC4', 'ITH3', 'ITH4', 'ITH5'],\n",
    "    'alpi': ['ITC1', 'ITC2', 'ITC4', 'ITH1', 'ITH2', 'ITH3', 'ITH4']\n",
    "}\n",
    "\n",
    "# Map extracted locations to NUTS2 codes\n",
    "def to_nuts2_custom(locations):\n",
    "    nuts_regions = set()\n",
    "    for loc in locations:\n",
    "        for key, value in location_to_nuts2_custom.items():            \n",
    "            if key == loc:\n",
    "                nuts_regions.update(value)\n",
    "                break \n",
    "    return list(nuts_regions)\n",
    "\n",
    "df_italy['nuts'] = df_italy['loc'].apply(lambda x: to_nuts2_custom(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping keywords to NUTS2 regions\n",
    "\n",
    "location_to_nuts2 = {\n",
    "    'abruzzo': ['ITF1'],\n",
    "    'aosta': ['ITC2'],\n",
    "    'daosta': ['ITC2'],\n",
    "    'basilicata': ['ITF5'],\n",
    "    'bolzano bozen': ['ITH1'],\n",
    "    'bolzanobozen': ['ITH1'],\n",
    "    'calabria': ['ITF6'],\n",
    "    'campania': ['ITF3'],\n",
    "    'emilia': ['ITH5'],\n",
    "    'emilia romagna': ['ITH5'],\n",
    "    'emiliaromagna': ['ITH5'],\n",
    "    'romagna': ['ITH5'],\n",
    "    'friuli venezia giulia': ['ITH4'],\n",
    "    'friulivenezia giulia': ['ITH4'],\n",
    "    'friuliveneziagiulia': ['ITH4'],\n",
    "    'lazio': ['ITI4'],\n",
    "    'liguria': ['ITC3'],\n",
    "    'lombardia': ['ITC4'],\n",
    "    'lombardy': ['ITC4'],\n",
    "    'marche': ['ITI3'],\n",
    "    'molise': ['ITF2'],\n",
    "    'piemonte': ['ITC1'],\n",
    "    'puglia': ['ITF4'],\n",
    "    'sardegna': ['ITG2'],\n",
    "    'sardinia': ['ITG2'],\n",
    "    'sicilia': ['ITG1'],\n",
    "    'sicily': ['ITG1'],\n",
    "    'toscana': ['ITI1'],\n",
    "    'trentino alto adige': ['ITH2'],\n",
    "    'trentinoalto adige': ['ITH2'],\n",
    "    'trentinoaltoadige': ['ITH2'],\n",
    "    'umbria': ['ITI2'],\n",
    "    'veneto': ['ITH3'],\n",
    "    \n",
    "    'monte bianco': ['ITC2']\n",
    "}\n",
    "\n",
    "# Map extracted locations to NUTS2 codes\n",
    "\n",
    "def to_nuts2(locations):\n",
    "    nuts_regions = set()\n",
    "    region_names = list(location_to_nuts2.keys())\n",
    "    for loc in locations:\n",
    "        for region in region_names:\n",
    "            if region in loc:\n",
    "                nuts_regions.update(location_to_nuts2[region])\n",
    "                loc = loc.replace(region, \"\")\n",
    "        remaining_parts = loc.strip().split()\n",
    "        for part in remaining_parts:\n",
    "            for region in region_names:\n",
    "                if region.startswith(part):\n",
    "                    nuts_regions.update(location_to_nuts2[region])\n",
    "                    break\n",
    "    return list(nuts_regions)\n",
    "\n",
    "df_italy['nuts'] = df_italy.apply(\n",
    "    lambda row: to_nuts2(row['loc']) if row['nuts'] == [] else row['nuts'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping keywords to NUTS3 regions\n",
    "\n",
    "location_to_nuts3_custom = {\n",
    "    'torino': ['ITC11'],\n",
    "    'vercelli': ['ITC12'],\n",
    "    'biella': ['ITC13'],\n",
    "    'verbano-cusio-ossola': ['ITC14'],\n",
    "    'novara': ['ITC15'],\n",
    "    'cuneo': ['ITC16'],\n",
    "    'asti': ['ITC17'],\n",
    "    'alessandria': ['ITC18'],\n",
    "    'imperia': ['ITC31'],\n",
    "    'savona': ['ITC32'],\n",
    "    'genova': ['ITC33'],\n",
    "    'la spezia': ['ITC34'],\n",
    "    'varese': ['ITC41'],\n",
    "    'como': ['ITC42'],\n",
    "    'lecco': ['ITC43'],\n",
    "    'sondrio': ['ITC44'],\n",
    "    'bergamo': ['ITC46'],\n",
    "    'brescia': ['ITC47'],\n",
    "    'pavia': ['ITC48'],\n",
    "    'lodi': ['ITC49'],\n",
    "    'cremona': ['ITC4A'],\n",
    "    'mantova': ['ITC4B'],\n",
    "    'milano': ['ITC4C'],\n",
    "    'milan': ['ITC4C'],\n",
    "    'monza e della brianza': ['ITC4D'],\n",
    "    'l’aquila': ['ITF11'],\n",
    "    'teramo': ['ITF12'],\n",
    "    'pescara': ['ITF13'],\n",
    "    'chieti': ['ITF14'],\n",
    "    'isernia': ['ITF21'],\n",
    "    'campobasso': ['ITF22'],\n",
    "    'caserta': ['ITF31'],\n",
    "    'benevento': ['ITF32'],\n",
    "    'napoli': ['ITF33'],\n",
    "    'avellino': ['ITF34'],\n",
    "    'salerno': ['ITF35'],\n",
    "    'taranto': ['ITF43'],\n",
    "    'brindisi': ['ITF44'],\n",
    "    'lecce': ['ITF45'],\n",
    "    'foggia': ['ITF46'],\n",
    "    'bari': ['ITF47'],\n",
    "    'barletta-andria-trani': ['ITF48'],\n",
    "    'potenza': ['ITF51'],\n",
    "    'matera': ['ITF52'],\n",
    "    'cosenza': ['ITF61'],\n",
    "    'crotone': ['ITF62'],\n",
    "    'catanzaro': ['ITF63'],\n",
    "    'vibo valentia': ['ITF64'],\n",
    "    'reggio calabria': ['ITF65'],\n",
    "    'trapani': ['ITG11'],\n",
    "    'palermo': ['ITG12'],\n",
    "    'messina': ['ITG13'],\n",
    "    'agrigento': ['ITG14'],\n",
    "    'caltanissetta': ['ITG15'],\n",
    "    'enna': ['ITG16'],\n",
    "    'catania': ['ITG17'],\n",
    "    'ragusa': ['ITG18'],\n",
    "    'siracusa': ['ITG19'],\n",
    "    'sassari': ['ITG2D'],\n",
    "    'nuoro': ['ITG2E'],\n",
    "    'cagliari': ['ITG2F'],\n",
    "    'oristano': ['ITG2G'],\n",
    "    'sud sardegna': ['ITG2H'],\n",
    "    'bolzano-bozen': ['ITH10'],\n",
    "    'trento': ['ITH20'],\n",
    "    'verona': ['ITH31'],\n",
    "    'vicenza': ['ITH32'],\n",
    "    'belluno': ['ITH33'],\n",
    "    'treviso': ['ITH34'],\n",
    "    'venezia': ['ITH35'],\n",
    "    'venice': ['ITH35'],\n",
    "    'padova': ['ITH36'],\n",
    "    'rovigo': ['ITH37'],\n",
    "    'pordenone': ['ITH41'],\n",
    "    'udine': ['ITH42'],\n",
    "    'gorizia': ['ITH43'],\n",
    "    'trieste': ['ITH44'],\n",
    "    'piacenza': ['ITH51'],\n",
    "    'parma': ['ITH52'],\n",
    "    'reggio nell’emilia': ['ITH53'],\n",
    "    'modena': ['ITH54'],\n",
    "    'bologna': ['ITH55'],\n",
    "    'ferrara': ['ITH56'],\n",
    "    'ravenna': ['ITH57'],\n",
    "    'forlì-cesena': ['ITH58'],\n",
    "    'rimini': ['ITH59'],\n",
    "    'massa-carrara': ['ITI11'],\n",
    "    'lucca': ['ITI12'],\n",
    "    'pistoia': ['ITI13'],\n",
    "    'firenze': ['ITI14'],\n",
    "    'prato': ['ITI15'],\n",
    "    'livorno': ['ITI16'],\n",
    "    'pisa': ['ITI17'],\n",
    "    'arezzo': ['ITI18'],\n",
    "    'siena': ['ITI19'],\n",
    "    'grosseto': ['ITI1A'],\n",
    "    'perugia': ['ITI21'],\n",
    "    'terni': ['ITI22'],\n",
    "    'pesaro e urbino': ['ITI31'],\n",
    "    'ancona': ['ITI32'],\n",
    "    'macerata': ['ITI33'],\n",
    "    'ascoli piceno': ['ITI34'],\n",
    "    'fermo': ['ITI35'],\n",
    "    'viterbo': ['ITI41'],\n",
    "    'rieti': ['ITI42'],\n",
    "    'roma': ['ITI43'],\n",
    "    'rome': ['ITI43'],\n",
    "    'latina': ['ITI44'],\n",
    "    'frosinone': ['ITI45'],\n",
    "    \n",
    "    'garda': ['ITC47','ITH20', 'ITH32'],\n",
    "    'maggiore': ['ITC14', 'ITC15', 'ITC41'],\n",
    "    'lago di como': ['ITC42', 'ITC43'],\n",
    "    'lago diseo': ['ITC46', 'ITC47'],\n",
    "    \n",
    "    'salento': ['ITF43', 'ITF44', 'ITF45'],\n",
    "    'polesine': ['ITH37'],\n",
    "    'tevere': ['ITI43'],\n",
    "    'reno': ['ITH54', 'ITH55', 'ITH56'],\n",
    "    'isonzo':['ITH43', 'ITH544'],\n",
    "    \n",
    "    'san martino':['N/A'],\n",
    "    'paese':['N/A'],\n",
    "    'montagna':['N/A'],\n",
    "    'duomo':['N/A']\n",
    "}\n",
    "\n",
    "# Map extracted locations to NUTS3 codes\n",
    "\n",
    "def to_nuts3_custom(locations):\n",
    "    nuts_regions = set()\n",
    "    region_names = list(location_to_nuts3_custom.keys())    \n",
    "    for loc in locations:\n",
    "        for region in region_names:\n",
    "            if region in loc:\n",
    "                nuts_regions.update(location_to_nuts3_custom[region])\n",
    "                break \n",
    "    return list(nuts_regions)\n",
    "\n",
    "df_italy['nuts'] = df_italy.apply(\n",
    "    lambda row: to_nuts3_custom(row['loc']) if row['nuts'] == [] else row['nuts'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where the nuts column is empty\n",
    "\n",
    "df_blank_nuts = df_italy[df_italy['nuts'].apply(lambda x: len(x) == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb487db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the NUTS3 code for a given location using the Nominatim geolocation API\n",
    "\n",
    "def get_nuts3(location):\n",
    "    geolocator = Nominatim(user_agent=\"nuts3_locator\")\n",
    "    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "    \n",
    "    try:\n",
    "        location_data = geocode(location, addressdetails=True, extratags=True)\n",
    "        if location_data and 'address' in location_data.raw:\n",
    "            address = location_data.raw['address']\n",
    "            print(address)\n",
    "            \n",
    "            if address.get('country_code') == 'it':\n",
    "                if 'ISO3166-2-lvl6' in address:\n",
    "                    return address['ISO3166-2-lvl6'], 'lvl6'\n",
    "                elif 'ISO3166-2-lvl4' in address:\n",
    "                    return address['ISO3166-2-lvl4'], 'lvl4'\n",
    "                elif 'ISO3166-2-lvl8' in address:\n",
    "                    return address['ISO3166-2-lvl8'], 'lvl8'\n",
    "    except (GeocoderTimedOut, RequestException) as e:\n",
    "        print(f\"Geocoding error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    return None, None\n",
    "\n",
    "def process_locations(df):\n",
    "    for idx, locations in df['loc'].items():\n",
    "        location_list = [loc.strip() for loc in locations]\n",
    "        nuts3_codes = []\n",
    "        nuts3_levels = []\n",
    "        \n",
    "        for location in location_list:\n",
    "            nuts3_code = None\n",
    "            level = None\n",
    "            retries = 3\n",
    "            while retries > 0:\n",
    "                try:\n",
    "                    nuts3_code, level = get_nuts3(location)\n",
    "                    break\n",
    "                except GeocoderTimedOut:\n",
    "                    retries -= 1\n",
    "                    time.sleep(2) \n",
    "            if nuts3_code is not None:\n",
    "                nuts3_codes.append(nuts3_code)\n",
    "                nuts3_levels.append(level)\n",
    "            time.sleep(1) \n",
    "            \n",
    "        seen = set()\n",
    "        unique_nuts3_codes = [code for code in nuts3_codes if not (code in seen or seen.add(code))]\n",
    "        \n",
    "        df.loc[idx, 'nuts3'] = ', '.join(unique_nuts3_codes)\n",
    "        df.loc[idx, 'level'] = ', '.join(nuts3_levels)\n",
    "        \n",
    "        print(f\"{locations}: {', '.join(unique_nuts3_codes)} (Levels: {', '.join(nuts3_levels)})\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "df_blank_nuts = process_locations(df_blank_nuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b91331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary Nominatim NUTS3 codes to normal NUTS3 codes\n",
    "\n",
    "nuts3_mapping = {\n",
    "    'IT-AG': 'ITG14',\n",
    "    'IT-AL': 'ITC18',\n",
    "    'IT-AN': 'ITI32',\n",
    "    'IT-AR': 'ITI18',\n",
    "    'IT-AP': 'ITI34',\n",
    "    'IT-AV': 'ITF34',\n",
    "    'IT-BA': 'ITF47',\n",
    "    'IT-BT': 'ITF48',\n",
    "    'IT-BL': 'ITH33',\n",
    "    'IT-BN': 'ITF32',\n",
    "    'IT-BG': 'ITC46',\n",
    "    'IT-BI': 'ITC13',\n",
    "    'IT-BO': 'ITH55',\n",
    "    'IT-BS': 'ITC47',\n",
    "    'IT-CA': 'ITG2F',\n",
    "    'IT-CL': 'ITG15',\n",
    "    'IT-CE': 'ITF31',\n",
    "    'IT-CT': 'ITG17',\n",
    "    'IT-CH': 'ITF14',\n",
    "    'IT-CO': 'ITC42',\n",
    "    'IT-CS': 'ITF61',\n",
    "    'IT-CR': 'ITC4A',\n",
    "    'IT-CN': 'ITC16',\n",
    "    'IT-EN': 'ITG16',\n",
    "    'IT-FM': 'ITI35',\n",
    "    'IT-FE': 'ITH56',\n",
    "    'IT-FI': 'ITI14',\n",
    "    'IT-FG': 'ITF46',\n",
    "    'IT-FC': 'ITH58',\n",
    "    'IT-FR': 'ITI45',\n",
    "    'IT-GE': 'ITC33',\n",
    "    'IT-GO': 'ITH43',\n",
    "    'IT-GR': 'ITI1A',\n",
    "    'IT-IM': 'ITC31',\n",
    "    'IT-IS': 'ITF21',\n",
    "    'IT-AQ': 'ITF11',\n",
    "    'IT-SP': 'ITC34',\n",
    "    'IT-LT': 'ITI44',\n",
    "    'IT-LE': 'ITF45',\n",
    "    'IT-LC': 'ITC43',\n",
    "    'IT-LI': 'ITI16',\n",
    "    'IT-LO': 'ITC49',\n",
    "    'IT-LU': 'ITI12',\n",
    "    'IT-MC': 'ITI33',\n",
    "    'IT-MN': 'ITC4B',\n",
    "    'IT-MS': 'ITI11',\n",
    "    'IT-ME': 'ITG13',\n",
    "    'IT-MI': 'ITC4C',\n",
    "    'IT-MO': 'ITH54',\n",
    "    'IT-MB': 'ITC4D',\n",
    "    'IT-NA': 'ITF33',\n",
    "    'IT-NO': 'ITC15',\n",
    "    'IT-PD': 'ITH36',\n",
    "    'IT-PA': 'ITG12',\n",
    "    'IT-PR': 'ITH52',\n",
    "    'IT-PV': 'ITC48',\n",
    "    'IT-PG': 'ITI21',\n",
    "    'IT-PU': 'ITI31',\n",
    "    'IT-PC': 'ITH51',\n",
    "    'IT-PN': 'ITH41',\n",
    "    'IT-PZ': 'ITF51',\n",
    "    'IT-BZ': 'ITH10',\n",
    "    'IT-TN': 'ITH20',\n",
    "    'IT-RG': 'ITG18',\n",
    "    'IT-RA': 'ITH57',\n",
    "    'IT-RC': 'ITF65',\n",
    "    'IT-RE': 'ITH53',\n",
    "    'IT-RI': 'ITI42',\n",
    "    'IT-RM': 'ITI43',\n",
    "    'IT-RO': 'ITH37',\n",
    "    'IT-SA': 'ITF35',\n",
    "    'IT-SS': 'ITG2D',\n",
    "    'IT-SV': 'ITC32',\n",
    "    'IT-SI': 'ITI19',\n",
    "    'IT-SO': 'ITC44',\n",
    "    'IT-SU': 'ITG2H',\n",
    "    'IT-TR': 'ITI22',\n",
    "    'IT-TO': 'ITC11',\n",
    "    'IT-TP': 'ITG11',\n",
    "    'IT-TV': 'ITH34',\n",
    "    'IT-UD': 'ITH42',\n",
    "    'IT-VA': 'ITC41',\n",
    "    'IT-VE': 'ITH35',\n",
    "    'IT-VB': 'ITC14',\n",
    "    'IT-VC': 'ITC12',\n",
    "    'IT-VR': 'ITH31',\n",
    "    'IT-VI': 'ITH32',\n",
    "    'IT-VT': 'ITI41',\n",
    "    \n",
    "    'IT-23': 'ITC2',\n",
    "    'IT-45': 'ITH3',\n",
    "    'IT-34': 'ITH4',\n",
    "    'IT-25': 'ITC4',\n",
    "    'IT-36': 'ITH5',\n",
    "    'IT-52': 'ITI1',\n",
    "    'IT-21': 'ITC1',\n",
    "    'IT-57': 'ITI4'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09017f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map Nominatim extracted locations to NUTS3 codes\n",
    "\n",
    "def map_nuts(nuts3_list, mapping):\n",
    "    if all(item in mapping for item in nuts3_list):\n",
    "        return [mapping.get(item) for item in nuts3_list]\n",
    "    else:\n",
    "        return ['']\n",
    "    \n",
    "df_blank_nuts['nuts3'] = df_blank_nuts['nuts3'].apply(lambda x: x.split(', '))\n",
    "df_blank_nuts['nuts'] = df_blank_nuts['nuts3'].apply(lambda x: map_nuts(x, nuts3_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc84fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the Nominatim results with previous results\n",
    "\n",
    "df_italy.loc[df_blank_nuts.index] = df_blank_nuts\n",
    "df_italy = df_italy.drop('loc', axis = 1)\n",
    "\n",
    "df_italy_nuts = df_italy[df_italy['nuts'].apply(lambda x: x != [''] and x != ['N/A'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08481929",
   "metadata": {},
   "source": [
    "### remove stopwords for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers and entities for embeddings, while drought-related locations are preserved\n",
    "\n",
    "def remove_loc_it(text):\n",
    "    doc = nlp_it(text)\n",
    "    new_text = text\n",
    "\n",
    "    preserve_keywords = ['po', 'tevere', 'lago', 'naviglio', 'canale', 'adda', 'ladda', 'oglio']\n",
    "\n",
    "    replacements = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['LOC', 'GPE']:\n",
    "            if not any(keyword in ent.text.lower() for keyword in preserve_keywords):\n",
    "                replacements.append((ent.start_char, ent.end_char))\n",
    "\n",
    "    for token in doc:\n",
    "        if token.like_num:\n",
    "            replacements.append((token.idx, token.idx + len(token.text)))\n",
    "\n",
    "    replacements.sort(reverse=True)\n",
    "\n",
    "    for start, end in replacements:\n",
    "        new_text = new_text[:start] + new_text[end:]\n",
    "\n",
    "    return new_text\n",
    "\n",
    "df_italy_nuts['noent_text'] = df_italy_nuts['process_text'].apply(remove_loc_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01066f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove stopwords and specific Italian stopwords\n",
    "\n",
    "italian_stopwords = set(stopwords.words('italian'))\n",
    "keywords = ['clima','climatica','climatici','cambiamento climatico','cambiamentoclimatico','caldo','temperatura',\n",
    "            'precipitazione','precipitazioni','pioggia','piogge','maltempo','siccità','siccita',\n",
    "            'cè','qui','via','ore','giorni','mesi','anni','così','già','fa','fatto',\n",
    "            'drought','temperature','climate','climateemergency','climatecrisis','climatechange','the']\n",
    "\n",
    "all_keywords = set(keywords + list(italian_stopwords))\n",
    "\n",
    "pattern = r'\\b(?:' + '|'.join(map(re.escape, all_keywords)) + r')\\b'\n",
    "\n",
    "df_italy_nuts['text_clean'] = df_italy_nuts['noent_text'].apply(lambda x: re.sub(pattern, '', x, flags=re.IGNORECASE))\n",
    "df_italy_nuts['text_clean'] = df_italy_nuts['text_clean'].str.strip().replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "df_embeddings = df_italy_nuts[df_italy_nuts['text_clean'] != ''].dropna(subset=['text_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc51c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings.to_excel('tweets/tweets_11578_clean.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twitter_data]",
   "language": "python",
   "name": "conda-env-twitter_data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
