{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ecbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = np.load('tweets/it_laser_11578.npy')\n",
    "sbert = np.load('tweets/it_sbert_11578.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f47c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('tweets/tweets_11578_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c370796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute silhouette scores for LASER-PCA\n",
    "\n",
    "pca_reducer = PCA(n_components = 2)\n",
    "laser_pca = pca_reducer.fit_transform(laser)\n",
    "\n",
    "cluster_range = [30, 40, 50, 60, 70, 80]\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters = k, random_state = 42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(laser_pca)\n",
    "    sil_score = silhouette_score(laser_pca, cluster_labels)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    print(f\"Silhouette Score for {k} clusters: {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2901b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute silhouette scores for LASER-UMAP\n",
    "\n",
    "umap_reducer = umap.UMAP(n_components = 2, random_state=42)\n",
    "laser_umap = umap_reducer.fit_transform(laser)\n",
    "\n",
    "cluster_range = [30, 40, 50, 60, 70, 80]\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters = k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(laser_umap)\n",
    "    sil_score = silhouette_score(laser_umap, cluster_labels)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    print(f\"Silhouette Score for {k} clusters: {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute silhouette scores for SBERT-PCA\n",
    "\n",
    "pca_reducer = PCA(n_components = 2)\n",
    "sbert_pca = pca_reducer.fit_transform(sbert)\n",
    "\n",
    "cluster_range = [30, 40, 50, 60, 70, 80]\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters = k, random_state = 42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(sbert_pca)\n",
    "    sil_score = silhouette_score(sbert_pca, cluster_labels)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    print(f\"Silhouette Score for {k} clusters: {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b27d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute silhouette scores for SBERT-UMAP\n",
    "\n",
    "umap_reducer = umap.UMAP(n_components = 2, random_state=42)\n",
    "sbert_umap = umap_reducer.fit_transform(sbert)\n",
    "\n",
    "cluster_range = [30, 40, 50, 60, 70, 80]\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters = k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(sbert_umap)\n",
    "    sil_score = silhouette_score(sbert_umap, cluster_labels)\n",
    "    silhouette_scores.append(sil_score)\n",
    "    print(f\"Silhouette Score for {k} clusters: {sil_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SSE to determine the optimal cluster number\n",
    "\n",
    "sse = []\n",
    "cluster_range = [30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]\n",
    "for k in cluster_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(sbert_umap)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cluster_range, sse, 'bo-', color='black')\n",
    "plt.xlabel('Number of Clusters', fontsize =16)\n",
    "plt.ylabel('Sum of Squared Errors', fontsize =16)\n",
    "plt.xticks(cluster_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce958c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of clusters to 50 and fit the KMeans model\n",
    "kmeans_model = KMeans(n_clusters=50, random_state=42, n_init=10)\n",
    "kmeans_model.fit(sbert_umap)\n",
    "\n",
    "df['n_50'] = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the cleaned text individual words for each tweet and get the top 5 most common keywords in each cluster\n",
    "\n",
    "\n",
    "df['keywords'] = df['text_noent_clean'].str.split()\n",
    "\n",
    "top_keywords_by_cluster = df.groupby('n_50')['keywords'].sum()\n",
    "\n",
    "def get_top_keywords(keywords, top_n=5):\n",
    "    keyword_counts = Counter(keywords)\n",
    "    return keyword_counts.most_common(top_n)\n",
    "\n",
    "df_top_keywords = top_keywords_by_cluster.apply(get_top_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_top_keywords.rename('top_keywords'), left_on='n_50', right_index=True)\n",
    "df = df.sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4977094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ff9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random subset for manual labeling\n",
    "\n",
    "df_random = df.groupby('n_50').apply(lambda x: x.sample(n=10, random_state=42)).reset_index(drop=True)\n",
    "df_random.to_excel('tweets/tweets_results/tweets_500_random.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the labeled category values within each cluster\n",
    "\n",
    "df_label = pd.read_excel('tweets/tweets_500_random.xlsx')\n",
    "\n",
    "categories = ['Agriculture', 'Water', 'Ecosystem', 'Economy', 'Society', 'General']\n",
    "cluster_sum = df_label.groupby('n_50')[categories].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign category scores to each cluster and map the scores back to tweets\n",
    "\n",
    "def assign_scores(count):\n",
    "    if count >= 6:\n",
    "        return 1\n",
    "    elif count >= 3:\n",
    "        return 0.5\n",
    "    elif count >= 1:\n",
    "        return 0.2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "cluster_scores = cluster_sum.applymap(assign_scores)\n",
    "cluster_scores = cluster_scores.reset_index()\n",
    "\n",
    "df_scores = df.merge(cluster_scores, on='n_50', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee02b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_excel('tweets/tweets_11578_scores.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f916851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings results\n",
    "\n",
    "sector_color_maps = {\n",
    "    \"Water\": cm.Blues,\n",
    "    \"Society\": cm.RdPu,\n",
    "    \"General\": cm.Greys,\n",
    "    \"Agriculture\": cm.YlOrBr,\n",
    "    \"Ecosystem\": cm.Greens,\n",
    "    \"Economy\": cm.Purples\n",
    "}\n",
    "\n",
    "# Map clusters to their dominant sectors\n",
    "cluster_to_category = {\n",
    "    0: \"Society\", 1: \"Water\", 2: \"Water\", 3: \"Agriculture\", 4: \"Society\",\n",
    "    5: \"Water\", 6: \"Water\", 7: \"Water\", 8: \"Agriculture\", 9: \"Water\",\n",
    "    10: \"General\", 11: \"General\", 12: \"Society\", 13: \"Water\", 14: \"General\",\n",
    "    15: \"General\", 16: \"Society\", 17: \"Society\", 18: \"Ecosystem\", 19: \"Society\",\n",
    "    20: \"Water\", 21: \"Society\", 22: \"Economy\", 23: \"Water\", 24: \"Agriculture\",\n",
    "    25: \"Water\", 26: \"Society\", 27: \"Agriculture\", 28: \"General\", 29: \"Water\",\n",
    "    30: \"Water\", 31: \"Society\", 32: \"Water\", 33: \"General\", 34: \"General\",\n",
    "    35: \"General\", 36: \"Society\", 37: \"Society\", 38: \"Ecosystem\", 39: \"Society\",\n",
    "    40: \"Water\", 41: \"Agriculture\", 42: \"Society\", 43: \"Society\", 44: \"General\",\n",
    "    45: \"Water\", 46: \"Society\", 47: \"Water\", 48: \"Society\", 49: \"Water\"\n",
    "}\n",
    "\n",
    "# Generate a color for each cluster using color maps\n",
    "cluster_colors = {}\n",
    "for category, color_map in sector_color_maps.items():\n",
    "    category_clusters = [cluster for cluster, cat in cluster_to_category.items() if cat == category]\n",
    "    num_clusters = len(category_clusters)\n",
    "    colors = color_map(np.linspace(0.4, 0.8, num_clusters))\n",
    "    for cluster, color in zip(category_clusters, colors):\n",
    "        cluster_colors[cluster] = color\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "unique_clusters = df['n_50'].unique()\n",
    "for cluster in unique_clusters:\n",
    "    cluster_points = sbert_umap[df['n_50'] == cluster]\n",
    "    color = cluster_colors.get(cluster, \"black\") \n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {cluster} ({cluster_to_category[cluster]})\", color=color, s=10, alpha=0.7)\n",
    "\n",
    "# Calculate centroids and add keyword labels only for clusters 18, 22, and 27\n",
    "for cluster in [18, 22, 27]:\n",
    "    if cluster in unique_clusters:\n",
    "        keywords = df[df['n_50'] == cluster]['top_keywords'].iloc[0]\n",
    "        keywords_text = ', '.join([keyword[0] for keyword in keywords[:3]])\n",
    "\n",
    "        label_text = f\"Cluster {cluster}\\n{keywords_text}\"\n",
    "\n",
    "        cluster_points = sbert_umap[df['n_50'] == cluster]\n",
    "        centroid = cluster_points.mean(axis=0)\n",
    "        \n",
    "        plt.text(centroid[0], centroid[1], label_text, fontsize=8, ha='center', va='center', \n",
    "                 bbox=dict(facecolor='white', alpha=0.6))\n",
    "\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.title(\"UMAP Visualization of Clustered Embeddings with Sector-Based Color Schemes\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fers]",
   "language": "python",
   "name": "conda-env-fers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
