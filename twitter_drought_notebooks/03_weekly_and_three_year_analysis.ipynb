{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d213c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('tweets/tweets_11578_scores.xlsx')\n",
    "columns = ['Agriculture', 'Water', 'Ecosystem', 'Economy', 'Society', 'General']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to week\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
    "df['month'] = df['date'].dt.month\n",
    "df['week'] = df['date'].dt.isocalendar().week \n",
    "\n",
    "df['week_start'] = df['date'] - pd.to_timedelta(df['date'].dt.weekday, unit='D')\n",
    "\n",
    "df_weekly = df.groupby('week_start')[columns].sum().reset_index()\n",
    "\n",
    "# Calculate normalized scores\n",
    "\n",
    "grand_total = df_weekly[columns].sum()\n",
    "df_weekly_perc = (df_weekly[columns] / grand_total) * 100\n",
    "df_weekly_perc['week_start'] = df_weekly['week_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ebe0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting category scores across weeks from May to August\n",
    "\n",
    "df_weekly_perc = df_weekly_perc[df_weekly_perc['week_start'].dt.month.isin([5, 6, 7, 8])]\n",
    "\n",
    "category_colors = {\n",
    "    'Agriculture': '#d95f0e',\n",
    "    'Water': '#3182bd',\n",
    "    'Ecosystem': '#31a354',\n",
    "    'Economy': '#756bb1',\n",
    "    'Society': '#dd1c77',\n",
    "    'General': '#636363'\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for category in category_colors.keys():\n",
    "    plt.plot(df_weekly_perc['week_start'], df_weekly_perc[category], marker='o', color=category_colors[category], label=category)\n",
    "\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Normalized score')\n",
    "plt.gca().xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcf2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_22 = pd.read_excel('tweets/tweets_11578_scores.xlsx')\n",
    "df_20_21 = pd.read_excel('tweets/tweets_nuts_20_21.xlsx')\n",
    "\n",
    "# Combine three years of tweets into one single df\n",
    "\n",
    "df_combined = pd.concat([df_22, df_20_21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the count of location extracted tweets by month\n",
    "\n",
    "df_combined['date'] = pd.to_datetime(df_combined['date'], errors='coerce')\n",
    "df_combined['month_year'] = df_combined['date'].dt.to_period('M')\n",
    "month_counts = df_combined['month_year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06273ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spi = pd.read_csv('eobs/spi3.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the point column containing latitude and longitude as a string in the format (lat, lon)\n",
    "\n",
    "spi[['lat', 'lon']] = spi['point'].str.strip('()').str.split(', ', expand=True).astype(float)\n",
    "\n",
    "# Create a geo df of Point geometries using the longitude and latitude columns\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(spi['lon'], spi['lat'])]\n",
    "spi_gdf = gpd.GeoDataFrame(spi, geometry=geometry)\n",
    "spi_gdf = spi_gdf.set_crs(epsg=4326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fa397",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('tweets/NUTS_RG_60M_2021_4326.shp', encoding='latin1')\n",
    "gdf_italy = gdf[gdf['CNTR_CODE'] == 'IT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1f2c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the shapefile\n",
    "\n",
    "gdf_italy.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81532028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial join and keep only points within the Italian boundaries\n",
    "\n",
    "spi_italy = gpd.sjoin(spi_gdf, gdf_italy, how='inner', predicate='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the start month\n",
    "\n",
    "spi_italy.columns[841]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spi_italy = spi_italy.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Define a threshold value to identify low SPI and count the gridded cells where SPI values are below the threshold\n",
    "\n",
    "threshold = -2\n",
    "\n",
    "selected_columns = spi_italy.columns[841:877]\n",
    "count_below_threshold = (spi_italy[selected_columns] < threshold).sum()\n",
    "\n",
    "low_spi = pd.DataFrame(count_below_threshold, columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aceeb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting the count of location extracted tweets and gridded cells with low SPI\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax1 = month_counts.plot(kind='bar', color='skyblue', edgecolor='black', width=0.8, label='Location Extracted Tweets')\n",
    "ax1.set_xlabel('Month-Year')\n",
    "ax1.set_ylabel('Count of Location Extracted Tweets')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(low_spi.index, low_spi['count'], color='orange', marker='o', linestyle='-', label='Gridded Cells with Low SPI')\n",
    "ax2.set_ylabel('Count of Gridded Cells with Low SPI3')\n",
    "\n",
    "lines1, labels1 = ax1.get_legend_handles_labels() \n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twitter_data]",
   "language": "python",
   "name": "conda-env-twitter_data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
